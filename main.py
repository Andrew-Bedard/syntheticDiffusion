import pandas as pd
import torch
from PIL import Image
import os
import streamlit as st
import numpy as np
from torch.utils.data import Subset
import random

from src.data.data_utils import CIFAR10Subsample, class_distribution_df, CustomDataset, load_and_transform_images, \
    load_cifar10_testset, load_cifar10_trainset
from src.viewer.visualization_utils import bar_chart_classes, plot_metrics, plot_per_class_accuracy, \
    plot_single_per_class_accuracy
from src.model.model import train_and_display, calculate_metrics, Net, train

torch.manual_seed(0)

# These are the classes in the cifar-10 dataset (in proper order)
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # TODO: do I still need this?

batch_size = 16
num_classes = 10
epochs = 30
cifar_percentage = 10

device = 'cuda' if torch.cuda.is_available() else 'cpu'  # If gpu exists use cuda
st.session_state.testset, st.session_state.testloader = load_cifar10_testset(batch_size)

def intro_page():
    st.title("Background")
    st.markdown("## What's it all about")
    st.markdown("""Welcome to this demonstration of using advanced techniques in artificial intelligence to generate 
    synthetic data for practical applications in data science. In this project, we'll be showcasing the power of Stable 
    Diffusion to generate synthetic data for a Convolutional Neural Network (CNN) image classification problem. By 
    augmenting our training data with synthetic images, we aim to improve the classification accuracy of the model. We've 
    chosen the CIFAR-10 dataset for this demonstration as it's lightweight and well-suited for our purposes. The CIFAR-10 
    dataset is widely recognized in the computer vision community, making it an ideal choice to demonstrate the 
    effectiveness of using synthetic data generated by Stable Diffusion.""")

    st.markdown("## CIFAR-10")
    st.markdown(" Let's take a look at the CIFAR-10 dataset")
    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cifar10.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='CIFAR-10 dataset example', use_column_width=True)

    st.markdown("## Methods")
    st.markdown("""
    The process we'll be following consists of three main steps:

    1. **Synthetic Data Generation**: We'll begin by generating a synthetic dataset of cat images using Stable Diffusion, 
    a powerful technique for creating realistic images that closely resemble their real-world counterparts. 

    2. **Data Transformation**: After obtaining the synthetic cat dataset, we'll transform it to match the format of the 
    CIFAR-10 dataset. This ensures that our CNN model can seamlessly process the synthetic data in conjunction with the 
    original dataset. 

    3. **Subsampling CIFAR-10**: To emphasize the impact of adding synthetic data to our model, we'll subsample the 
    CIFAR-10 dataset, working with a smaller number of images than typically used. This simulates a situation where 
    limited data is available, and the addition of synthetic images can provide a significant boost in classification 
    performance.

    By following these steps, we aim to demonstrate the potential benefits of incorporating synthetic data generated 
    using Stable Diffusion into a CNN model for image classification. This demonstration will showcase the practical 
    implications of using synthetic data to improve model performance in real-world applications.""")

    st.markdown("""
    Having generated a collection of realistic looking cat images we have to transform the format to match that of the
    CIFAR-10 dataset. The most important change is that we have to downsample our 512x512 images to 32x32""")

    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cat_to_cat.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='Resize of synthetic cat images to CIFAR-10 format', use_column_width=True)


def synCats_page():
    st.title("Generating Synthetic Images of cats")
    st.markdown("")
    st.markdown("[Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)",
                unsafe_allow_html=True)

def preCalc_page():


    # def train_cifar_model_with_percentage(percentage, trainset, trainloader, device):
    #     """
    #     Trains a CIFAR-10 classifier model with a specified percentage of cat images in the training dataset.
    #
    #     This function creates a new Subset of the training dataset with the specified percentage of cat images,
    #     then trains a new model using the modified dataset.
    #
    #     Args:
    #         percentage (float): The percentage of cat images to include in the training dataset, in the range [0, 100].
    #         trainset (torch.utils.data.Dataset): The original CIFAR-10 training dataset.
    #         trainloader (torch.utils.data.DataLoader): The original DataLoader for the CIFAR-10 training dataset.
    #         device (torch.device): The device to use for training the model (e.g., 'cpu' or 'cuda').
    #
    #     Returns:
    #         model (Net): The trained CIFAR-10 classifier model.
    #     """
    #     # Find the indices of the cat images in the trainset
    #     cat_indices = [i for i, (image, label) in enumerate(trainset) if
    #                    label == 3]  # Assuming cat class has a label of 3
    #
    #     # Calculate the number of cat images to include in the subsampled dataset
    #     num_cat_images = int(len(cat_indices) * (percentage / 100))
    #
    #     # Randomly choose the cat images to include
    #     chosen_cat_indices = random.sample(cat_indices, num_cat_images)
    #
    #     # Find the indices of the non-cat images in the trainset
    #     non_cat_indices = [i for i in range(len(trainset)) if i not in cat_indices]
    #
    #     # Combine the chosen cat image indices with the non-cat image indices
    #     new_trainset_indices = non_cat_indices + chosen_cat_indices
    #
    #     # Create a new Subset with the specified percentage of cat images
    #     new_trainset = Subset(trainset, new_trainset_indices)
    #
    #     # Create a new DataLoader with the modified trainset
    #     new_trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=trainloader.batch_size, shuffle=True,
    #                                                   num_workers=trainloader.num_workers)
    #
    #     # Train the model using the modified trainloader
    #     model = Net()
    #     model.to(device)
    #     train(model, new_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
    #           momentum=0.9)
    #
    #     return model
    #
    #
    # def train_cifar_model_with_custom_cats(percentage, trainset, custom_images, trainloader, device):
    #     # Find the indices of the cat images in the trainset
    #     cat_indices = [i for i, (image, label) in enumerate(trainset) if
    #                    label == 3]  # Assuming cat class has a label of 3
    #
    #     # Find the indices of the non-cat images in the trainset
    #     non_cat_indices = [i for i in range(len(trainset)) if i not in cat_indices]
    #
    #     # Extract non-cat images and labels
    #     non_cat_images = [trainset[i][0] for i in non_cat_indices]
    #     non_cat_labels = [trainset[i][1] for i in non_cat_indices]
    #
    #     # Calculate the number of synthetic cat images to include
    #     num_synthetic_cat_images = int(len(cat_indices) * (percentage / 100))
    #
    #     # Create custom labels (all cat obviously)
    #     custom_labels = len(custom_images) * [3]
    #
    #     # Randomly choose the synthetic cat images to include
    #     indices = torch.randperm(len(custom_images))[:num_synthetic_cat_images]
    #     chosen_synthetic_cat_images = custom_images[indices]
    #     chosen_synthetic_cat_labels = [custom_labels[i] for i in indices.tolist()]
    #
    #     # Stack non-cat images and chosen synthetic cat images
    #     non_cat_images = torch.stack(non_cat_images)
    #
    #     # Concatenate non-cat images and chosen synthetic cat images
    #     new_trainset_images = torch.cat((non_cat_images, chosen_synthetic_cat_images), dim=0)
    #
    #     # Combine the non-cat labels with the chosen synthetic cat labels
    #     new_trainset_labels = non_cat_labels + chosen_synthetic_cat_labels
    #
    #     # Create a new custom dataset with the specified percentage of synthetic cat images
    #     new_trainset = CustomDataset(new_trainset_images, new_trainset_labels)
    #
    #     # Create a new DataLoader with the modified trainset
    #     new_trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=trainloader.batch_size, shuffle=True,
    #                                                   num_workers=trainloader.num_workers)
    #
    #     # Train the model using the modified trainloader
    #     model = Net()
    #     model.to(device)
    #     train(model, new_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001, momentum=0.9)
    #
    #     return model

    def train_cifar_model_with_cats(percentage, trainset, trainloader, device, custom_images=None):
        # Find the indices of the cat images in the trainset
        cat_indices = [i for i, (image, label) in enumerate(trainset) if
                       label == 3]  # Assuming cat class has a label of 3

        # Find the indices of the non-cat images in the trainset
        non_cat_indices = [i for i in range(len(trainset)) if i not in cat_indices]

        # Extract non-cat images and labels
        non_cat_images = [trainset[i][0] for i in non_cat_indices]
        non_cat_labels = [trainset[i][1] for i in non_cat_indices]

        # Calculate the number of cat images to include
        num_cat_images = int(len(cat_indices) * (percentage / 100))

        if num_cat_images > 0:
            if custom_images is None:
                # Randomly choose the cat images to include
                chosen_cat_indices = random.sample(cat_indices, num_cat_images)
                chosen_cat_images = [trainset[i][0] for i in chosen_cat_indices]
                chosen_cat_labels = [trainset[i][1] for i in chosen_cat_indices]

                # Convert chosen_cat_images to a tensor
                chosen_cat_images = torch.stack(chosen_cat_images)
            else:
                # Create custom labels (all cat obviously)
                custom_labels = len(custom_images) * [3]

                # Randomly choose the synthetic cat images to include
                indices = torch.randperm(len(custom_images))[:num_cat_images]
                chosen_cat_images = custom_images[indices]
                chosen_cat_labels = [custom_labels[i] for i in indices.tolist()]

            # Stack non-cat images and chosen cat images
            non_cat_images = torch.stack(non_cat_images)

            # Concatenate non-cat images and chosen cat images
            new_trainset_images = torch.cat((non_cat_images, chosen_cat_images), dim=0)

            # Combine the non-cat labels with the chosen cat labels
            new_trainset_labels = non_cat_labels + chosen_cat_labels
        else:
            new_trainset_images = torch.stack(non_cat_images)
            new_trainset_labels = non_cat_labels

        # Create a new custom dataset with the specified percentage of cat images
        new_trainset = CustomDataset(new_trainset_images, new_trainset_labels)

        # Create a new DataLoader with the modified trainset
        new_trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=trainloader.batch_size, shuffle=True,
                                                      num_workers=trainloader.num_workers)

        # Train the model using the modified trainloader
        model = Net()
        model.to(device)
        train(model, new_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001, momentum=0.9)

        return model

    def train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device, custom_images=None):
        all_metrics = {p: [] for p in percentages}

        for p in percentages:
            print(p)
            for _ in range(num_trials):
                if custom_images is None:
                    model = train_cifar_model_with_cats(p, trainset, trainloader, device)
                else:
                    model = train_cifar_model_with_cats(p, trainset, trainloader, device, custom_images=custom_images)

                metrics = calculate_metrics(model, testloader, device)
                all_metrics[p].append(metrics)

        return all_metrics

    def average_metrics(all_metrics, num_trials):
        averaged_metrics = {}

        for p in all_metrics:
            averaged = {
                'accuracy': 0,
                'per_class_accuracy': np.zeros(10),
                'precision': np.zeros(10),
                'recall': np.zeros(10),
                'f1_score': np.zeros(10)
            }

            for metrics in all_metrics[p]:
                averaged['accuracy'] += metrics['accuracy']
                averaged['per_class_accuracy'] += np.array(metrics['per_class_accuracy'])
                averaged['precision'] += np.array(metrics['precision'])
                averaged['recall'] += np.array(metrics['recall'])
                averaged['f1_score'] += np.array(metrics['f1_score'])

            averaged['accuracy'] /= num_trials
            averaged['per_class_accuracy'] /= num_trials
            averaged['precision'] /= num_trials
            averaged['recall'] /= num_trials
            averaged['f1_score'] /= num_trials

            averaged_metrics[p] = averaged

        return averaged_metrics


    st.markdown("WARNING! Depending on how many trails you select, pressing the following button will take a long "
                "time to complete")
    num_trials = st.selectbox('Select number of trails to run per % holdout of cat images:', list(range(1, 11)))
    if st.button("Perform batch training/metrics for real cats"):

        # trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
        trainset, trainloader = load_cifar10_trainset()
        testset, testloader = load_cifar10_testset()

        st.title("Pre-calculated results")

        percentages = [0, 20, 40, 60, 80, 100]
        # percentages = [0, 10]
        # num_trials = 10

        # Assuming you have your trainset, trainloader, testloader, and device set up
        all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device)
        averaged_metrics = average_metrics(all_metrics, num_trials)

        metrics_df = pd.DataFrame(averaged_metrics)
        metrics_df.to_csv('data/precalc_metrics_real1.csv')  # TODO: this does not save the correct name for the first
        # column, has to edited manually as 'metric'
        st.dataframe(metrics_df)

    if st.button("Perform batch training/metrics for synthetic cats"):

        # trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
        trainset, trainloader = load_cifar10_trainset()
        testset, testloader = load_cifar10_testset()

        st.title("Pre-calculated results")

        percentages = [0, 20, 40, 60, 80, 100]
        # percentages = [0, 10]
        # num_trials = 10

        synthetic_imgDir = "..\\syntheticDiffusion\\data\\synthetic_cats\\"
        custom_images = load_and_transform_images(synthetic_imgDir)

        # Assuming you have your trainset, trainloader, testloader, and device set up
        all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device, custom_images=custom_images)
        averaged_metrics = average_metrics(all_metrics, num_trials)

        metrics_df = pd.DataFrame(averaged_metrics)
        metrics_df.to_csv('data/precalc_metrics_synthetic1.csv')
        st.dataframe(metrics_df)


    # if 'batch_figure' in st.session_state:
    #     st.pyplot(st.session_state.batch_figure)

# def preCalc_page():
#
#     df = pd.read_csv("data/test.csv")
#     import plotly.graph_objects as go
#
#     # Function to plot the line plot for each metric
#     def plot_metric(metric_name, class_index):
#         fig = go.Figure()
#
#         for i in range(10):  # Assuming there are 10 classes in the CIFAR-10 dataset
#             fig.add_trace(go.Scatter(x=df.columns[1:],
#                                      y=[float(x.strip()[1:-1].split()[i]) for x in
#                                         df.loc[df['metric'] == metric_name].values[0][1:]],
#                                      mode='lines+markers',
#                                      name=f'Class {i}'))
#
#         fig.update_layout(title=f'{metric_name} for Class {class_index} across Models',
#                           xaxis_title='Percentage of Cat Images',
#                           yaxis_title=f'{metric_name}')
#
#         return fig
#
#     # Display line plots for each metric
#     st.plotly_chart(plot_metric('precision', 0))
#     st.plotly_chart(plot_metric('recall', 0))
#     st.plotly_chart(plot_metric('f1_score', 0))
#
#     def plot_accuracy():
#         fig = go.Figure()
#
#         fig.add_trace(go.Scatter(x=df.columns[1:],
#                                  y=df.loc[df['metric'] == 'accuracy'].values[0][1:],
#                                  mode='lines+markers',
#                                  name='Accuracy'))
#
#         fig.update_layout(title='Overall Accuracy across Models',
#                           xaxis_title='Percentage of Cat Images',
#                           yaxis_title='Accuracy')
#
#         return fig
#
#     st.plotly_chart(plot_accuracy())


def handsOn_page():

    st.title("Experiment with Synthetic Diffusion")

    # Let's take a look at the distribution of classes in our CIFAR-10 subsample
    st.markdown("CIFAR-10 is a highly curated dataset with 50,000 images in the training set that are all perfectly "
                "balanced. Because we are doing some training and experimentation locally, we might not want to wait "
                "for a model to train using 50,000 images, additionally we really want to showcase the difference in "
                "performance when we are in a situation where we don't have all the data we would like, so right away "
                "let's subsample the CIFAR-10 dataset uniformly to 10% of it's original size")
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")

    st.markdown("Let's do some sampling")
    # Create a horizontal container
    container = st.container()
    sampling_method_options = ["uniform", "random"]
    selected_sampling_method = container.radio("Select sampling method", sampling_method_options, index=0)
    st.write(f"Selected sampling method: {selected_sampling_method}")

    trainset, trainloader = load_cifar10_trainset(cifar_percentage, batch_size, sample_method=selected_sampling_method)
    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    class_counts_df = class_distribution_df(trainset)
    fig = bar_chart_classes(class_counts_df)
    st.pyplot(fig)

    st.markdown("""We should now benchmark this base CIFAR-10 model with this subsampled training set. You can either 
    choose to load the CIFAR-10 base model that was included in the repository, or train a new one yourself on the 
    training set that was created to produce the previous bar char""")

    # Check if the cifar10_base_model.pt exists
    model_exists = os.path.exists("data/models/cifar10_base_model.pt")

    # Create two columns for placing the buttons side by side
    col1, col2 = st.columns(2)

    # Display the button for training the base model in the first column
    if col1.button('Train CIFAR-10 base model'):
        train_and_display('cifar_base', trainloader, st.session_state.testloader, device, epochs)

    # If the base model file exists, display the button for using the existing model in the second column
    if model_exists:
        if col2.button('Use existing CIFAR-10 base model'):
            # Instantiate the model and load the state_dict from the file
            st.session_state.cifar_net = Net()
            st.session_state.cifar_net.load_state_dict(torch.load("data/models/cifar10_base_model.pt"))
            st.session_state.cifar_net.to(device)

            # Calculate the metrics for the existing model
            cifar_metrics = calculate_metrics(st.session_state.cifar_net, st.session_state.testloader, device)
            st.session_state.cifar_net_accuracy = cifar_metrics['accuracy']
            st.session_state.cifar_net_per_class_accuracy = cifar_metrics['per_class_accuracy']

    # Show the net accuracy for the base model
    if 'cifar_base' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_base['metrics']['accuracy'] * 100:.2f}%")
        basecifar_fig = plot_single_per_class_accuracy(st.session_state.cifar_base['metrics']['per_class_accuracy'],
                                                       labels,
                                                       'CFIAR-10 base model')
        st.pyplot(basecifar_fig)

    st.markdown("Great! We now have a base model trained on the subsampled CIFAR-10 dataset, and it should work "
                "reasonably well considering the simplicitly of our CNN and the size of the dataset. However, "
                "in real world applications we would be quite lucky to have a real dataset that is totally"
                "balanced across all class labels, so let's do some further ")

    # Create a button to decrease cat samples
    # If the button is pressed, show the slider and store its value in the session state
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")
    cat_proportion = st.slider("% of total cat images to keep:", min_value=0, max_value=90, value=50, step=10)
    cat_proportion = max(0, cat_proportion/100)
    st.session_state.cat_proportion = cat_proportion
    st.session_state.cat_num = cat_proportion * 10 * 500  # TODO: this should not be hardcoded like it is

    #
    # # If the session state has a cat_proportion, use it to load the data and display the chart
    # if "cat_proportion" in st.session_state:
    #     # TODO: to make this more performant, we should not be using load_cifar10 but instead subsample the
    #     #  trainset we already have
    #     trainset, trainloader, testset, testloader = load_cifar10(percentage=10,
    #                                                               cat_proportion=st.session_state.cat_proportion)
    #
    #     st.markdown("Let's take a look at the distribution of classes for our subsampled dataset now")
    #     class_counts_df = class_distribution_df(trainset)
    #     # TODO: maybe this chart can be replaced by a bokeh one
    #     fig = bar_chart_classes(class_counts_df)
    #     st.pyplot(fig)
    #
    #     # We don't want the load_cifar10 function to run again unless there has been a change in cat_proportion,
    #     # so we delete the session state for the variable after using it
    #     del st.session_state.cat_proportion

    st.markdown("""Depending on your choice of the proportion of cat images, we should have an unbalanced dataset 
    with fewer cat images than any other class. This is a situation we would normally try to avoid, so obviously, 
    we should start adding our own synthetically created cat images to the training set to suppliment it!""")

    # ... (Load and transform synthetic images)
    synthetic_imgDir = "..\\syntheticDiffusion\\data\\synthetic_cats\\"
    custom_images = load_and_transform_images(synthetic_imgDir)
    custom_labels = len(custom_images) * [3]  # Your assigned labels(cat)

    # Define slider for selecting number of custom images to add
    st.markdown("""Use the slider below to set the number of synthetic cat images to add to the training data. 
    By default it's set to fill the missing number of cat images, however you can add as many or few as you'd like. 
    We can compare the relative performance by trying multiple values""")
    num_custom_images = st.slider('Select number of custom images to add to dataset', 0,
                                  (len(custom_images) - len(custom_images) % 50),
                                  value=(500 - int(st.session_state.cat_num)), step=50)

    # Normalize CIFAR-10 images
    cfar_images = [trainset[i][0] for i in range(len(trainset))]
    cfar_images = torch.stack(cfar_images)

    # Concatenate our synthetic images with CIFAR-10 images
    custom_train_images = torch.cat((cfar_images, custom_images[:num_custom_images]), dim=0)

    # Extract targets from the CIFAR-10 Subsample
    cfar_targets = [trainset[i][1] for i in range(len(trainset))]
    custom_train_labels = cfar_targets + custom_labels[:num_custom_images]

    # Create a custom dataloader for our new combined dataset
    custom_trainset = CustomDataset(custom_train_images, custom_train_labels)
    custom_trainloader = torch.utils.data.DataLoader(custom_trainset, batch_size=batch_size,
                                                     shuffle=True, num_workers=0)

    # Initialize variables to store the previous custom model's accuracies in the session state
    if 'prev_custom_net_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_accuracy = None

    if 'prev_custom_net_per_class_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_per_class_accuracy = None

    # Create a button for triggering the training process
    # if st.button('Train synthetically enhanced model'):
    #
    #     # Create instance of your model
    #     custom_net = Net()
    #     custom_net.to(device)
    #
    #     # Display a message while the model is being trained
    #     training_message = st.empty()
    #     training_message.text("Training custom model...")
    #
    #     # Create a progress bar
    #     progress_bar = st.progress(0)
    #
    #     # Train the networks using the custom and CIFAR-10 dataloaders
    #     train(custom_net, custom_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
    #           momentum=0.9,
    #           progress_callback=update_progress, progress_bar=progress_bar)
    #
    #     # Remove the progress bar after training is complete
    #     progress_bar.empty()
    #
    #     # Clear the message and display the results
    #     training_message.empty()
    #
    #     metrics = calculate_metrics(custom_net, testloader, device, len(classes))
    #
    #     # Display overall accuracy
    #     st.subheader("Overall Model Accuracy")
    #     st.write(f"Custom model accuracy: {metrics['accuracy'] * 100:.2f}%")
    #     # st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy:.2f}%")
    #
    #     # Plot per-class accuracy
    #     st.subheader("Per-class Model Accuracy")
    #
    #     fig = plot_per_class_accuracy(metrics, st.session_state.cifar_net_per_class_accuracy, labels,
    #                                   ['Custom model', 'CIFAR-10 Base model'])
    #
    #     st.pyplot(fig)
    #
    #     # Compare the new custom model with the previous custom model if it exists
    #     if st.session_state.prev_custom_net_accuracy is not None:
    #         st.subheader("Comparison with the Previous Custom Model")
    #         fig2 = plot_per_class_accuracy(metrics, st.session_state.prev_custom_net_per_class_accuracy, labels,
    #                                        ['Current Custom Model', 'Previous Custom Model'])
    #
    #         fig2.tight_layout()
    #
    #         st.pyplot(fig2)
    #
    #     # Store the previous custom model's accuracies before updating the current ones
    #     st.session_state.prev_custom_net_accuracy = metrics['accuracy']
    #     st.session_state.prev_custom_net_per_class_accuracy = metrics['per_class_accuracy']

def comparison_page():
    st.markdown("Comparison with other methods like traditional cropping flipping...")

def network_page():
    st.markdown("Network")

def debugging_page():
    # This page exists for debugging purposes

    import torch
    import io

    # ... your existing code ...

    if 'cifar_net_accuracy' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy * 100:.2f}%")

        # Save the model to a binary format (PyTorch)
        model_binary = io.BytesIO()
        torch.save(st.session_state.cifar_net.state_dict(), model_binary)
        model_binary.seek(0)

        # Create a download button for the model
        st.download_button(
            label="Download CIFAR-10 base model",
            data=model_binary,
            file_name="cifar10_base_model.pt",
            mime="application/octet-stream"
        )



def main():
    st.sidebar.title("Navigation")

    # Mapping of pages to their respective functions
    pages = {
        "Introduction": intro_page,
        "Synthetic Cats": synCats_page,
        #"Network": network_page,
        "Pre-calculated results": preCalc_page,
        "Hands-on": handsOn_page,
        "Comparison": comparison_page,
        "Debugging": debugging_page
    }

    page_list = list(pages.keys())

    selected_page = st.sidebar.radio("Go to", page_list)

    st.markdown("# Synthetic Diffusion")

    # Call the function corresponding to the selected page
    pages[selected_page]()

# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    main()



