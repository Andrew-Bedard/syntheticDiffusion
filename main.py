import torch
import torchvision
import torchvision.transforms as transforms
from PIL import Image
import os
import streamlit as st

from src.data.data_utils import CIFAR10Subsample, class_distribution_df, CustomDataset, load_and_transform_images
from src.viewer.visualization_utils import bar_chart_classes, plot_metrics, plot_per_class_accuracy, \
    plot_single_per_class_accuracy
from src.model.model import train_and_display, calculate_metrics, Net

torch.manual_seed(0)

@st.cache_resource
def load_cifar10(percentage=10, cat_proportion=0.1):
    """

    :param percentage:
    :param cat_proportion:
    :return:
    """

    def normalize_class_proportions(class_proportions, target_class, new_proportion):
        """

        :param class_proportions:
        :param target_class:
        :param new_proportion:
        :return:
        """
        adjusted_proportions = class_proportions.copy()
        adjusted_proportions[target_class] = new_proportion

        sum_proportions = sum(adjusted_proportions.values())
        normalized_proportions = {key: value / sum_proportions for key, value in adjusted_proportions.items()}

        return normalized_proportions

    transform = transforms.Compose(
        [transforms.ToTensor(),
         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

    class_proportions = {'airplane': 0.1,
                         'automobile': 0.1,
                         'bird': 0.1,
                         'cat': cat_proportion,  # Pass the cat_proportion here
                         'deer': 0.1,
                         'dog': 0.1,
                         'frog': 0.1,
                         'horse': 0.1,
                         'ship': 0.1,
                         'truck': 0.1
                         }

    # Normalize the class proportions based on the new cat_proportion
    normalized_proportions = normalize_class_proportions(class_proportions, 'cat', cat_proportion)

    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)

    trainset = CIFAR10Subsample(root='./data', train=True, transform=transform, percentage=percentage,
                                class_proportions=class_proportions)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)

    return trainset, trainloader, testset, testloader


# These are the classes in the cifar-10 dataset (in proper order)
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # TODO: do I still need this?

batch_size = 16
num_classes = 10
epochs = 30
cifar_percentage = 10

device = 'cuda' if torch.cuda.is_available() else 'cpu'  # If gpu exists use cuda


def page1():
    st.title("Background")
    st.markdown("## What's it all about")
    st.markdown("""Welcome to this demonstration of using advanced techniques in artificial intelligence to generate 
    synthetic data for practical applications in data science. In this project, we'll be showcasing the power of Stable 
    Diffusion to generate synthetic data for a Convolutional Neural Network (CNN) image classification problem. By 
    augmenting our training data with synthetic images, we aim to improve the classification accuracy of the model. We've 
    chosen the CIFAR-10 dataset for this demonstration as it's lightweight and well-suited for our purposes. The CIFAR-10 
    dataset is widely recognized in the computer vision community, making it an ideal choice to demonstrate the 
    effectiveness of using synthetic data generated by Stable Diffusion.""")

    st.markdown("## CIFAR-10")
    st.markdown(" Let's take a look at the CIFAR-10 dataset")
    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cifar10.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='CIFAR-10 dataset example', use_column_width=True)

    st.markdown("## Methods")
    st.markdown("""
    The process we'll be following consists of three main steps:

    1. **Synthetic Data Generation**: We'll begin by generating a synthetic dataset of cat images using Stable Diffusion, 
    a powerful technique for creating realistic images that closely resemble their real-world counterparts. 

    2. **Data Transformation**: After obtaining the synthetic cat dataset, we'll transform it to match the format of the 
    CIFAR-10 dataset. This ensures that our CNN model can seamlessly process the synthetic data in conjunction with the 
    original dataset. 

    3. **Subsampling CIFAR-10**: To emphasize the impact of adding synthetic data to our model, we'll subsample the 
    CIFAR-10 dataset, working with a smaller number of images than typically used. This simulates a situation where 
    limited data is available, and the addition of synthetic images can provide a significant boost in classification 
    performance.

    By following these steps, we aim to demonstrate the potential benefits of incorporating synthetic data generated 
    using Stable Diffusion into a CNN model for image classification. This demonstration will showcase the practical 
    implications of using synthetic data to improve model performance in real-world applications.""")

    st.markdown("""
    Having generated a collection of realistic looking cat images we have to transform the format to match that of the
    CIFAR-10 dataset. The most important change is that we have to downsample our 512x512 images to 32x32""")

    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cat_to_cat.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='Resize of synthetic cat images to CIFAR-10 format', use_column_width=True)


def page2():
    st.title("Generating Synthetic Images of cats")
    st.markdown("")
    st.markdown("[Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)",
                unsafe_allow_html=True)


# def page3():
#     st.markdown("WARNING! Depending on how many trails you select, pressing the following button will take a long "
#                 "time to complete")
#     num_trials = st.selectbox('Select number of trails to run per % holdout of cat images:', list(range(1, 11)))
#     if st.button("Perform batch training/metrics"):
#
#         trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
#
#         st.title("Pre-calculated results")
#
#         from torch.utils.data import Subset
#         import random
#
#         def train_cifar_model_with_percentage(percentage, trainset, trainloader, device):
#             # Find the indices of the cat images in the trainset
#             cat_indices = [i for i, (image, label) in enumerate(trainset) if
#                            label == 3]  # Assuming cat class has a label of 3
#
#             # Calculate the number of cat images to include in the subsampled dataset
#             num_cat_images = int(len(cat_indices) * (percentage / 100))
#
#             # Randomly choose the cat images to include
#             chosen_cat_indices = random.sample(cat_indices, num_cat_images)
#
#             # Find the indices of the non-cat images in the trainset
#             non_cat_indices = [i for i in range(len(trainset)) if i not in cat_indices]
#
#             # Combine the chosen cat image indices with the non-cat image indices
#             new_trainset_indices = non_cat_indices + chosen_cat_indices
#
#             # Create a new Subset with the specified percentage of cat images
#             new_trainset = Subset(trainset, new_trainset_indices)
#
#             # Create a new DataLoader with the modified trainset
#             new_trainloader = torch.utils.data.DataLoader(new_trainset, batch_size=trainloader.batch_size, shuffle=True,
#                                                           num_workers=trainloader.num_workers)
#
#             # Train the model using the modified trainloader
#             model = Net()
#             model.to(device)
#             train(model, new_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
#                   momentum=0.9)
#
#             return model
#
#         def train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device):
#             all_metrics = {p: [] for p in percentages}
#
#             for p in percentages:
#                 print(p)
#                 for _ in range(num_trials):
#                     model = train_cifar_model_with_percentage(p, trainset, trainloader, device)
#                     metrics = calculate_metrics(model, testloader, device)
#                     all_metrics[p].append(metrics)
#
#             return all_metrics
#
#         def average_metrics(all_metrics, num_trials):
#             averaged_metrics = {}
#
#             for p in all_metrics:
#                 averaged = {
#                     'accuracy': 0,
#                     'per_class_accuracy': np.zeros(10),
#                     'precision': np.zeros(10),
#                     'recall': np.zeros(10),
#                     'f1_score': np.zeros(10)
#                 }
#
#                 for metrics in all_metrics[p]:
#                     averaged['accuracy'] += metrics['accuracy']
#                     averaged['per_class_accuracy'] += np.array(metrics['per_class_accuracy'])
#                     averaged['precision'] += np.array(metrics['precision'])
#                     averaged['recall'] += np.array(metrics['recall'])
#                     averaged['f1_score'] += np.array(metrics['f1_score'])
#
#                 averaged['accuracy'] /= num_trials
#                 averaged['per_class_accuracy'] /= num_trials
#                 averaged['precision'] /= num_trials
#                 averaged['recall'] /= num_trials
#                 averaged['f1_score'] /= num_trials
#
#                 averaged_metrics[p] = averaged
#
#             return averaged_metrics
#
#         percentages = [0, 25, 50, 75, 100]
#         # num_trials = 10
#
#         # Assuming you have your trainset, trainloader, testloader, and device set up
#         all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device)
#         averaged_metrics = average_metrics(all_metrics, num_trials)
#
#         # Plot the metrics
#         metrics_history = [averaged_metrics[p] for p in percentages]
#         st.session_state.batch_figure = plot_metrics(metrics_history)
#
#     if 'batch_figure' in st.session_state:
#         st.pyplot(st.session_state.batch_figure)
def page3():
    st.markdown("DUMMY")

def page4():
    trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

    st.title("Experiment with Synthetic Diffusion")

    # Let's take a look at the distribution of classes in our CIFAR-10 subsample
    st.markdown("CIFAR-10 is a highly curated dataset with 50,000 images in the training set that are all perfectly "
                "balanced. Because we are doing some training and experimentation locally, we might not want to wait "
                "for a model to train using 50,000 images, additionally we really want to showcase the difference in "
                "performance when we are in a situation where we don't have all the data we would like, so right away "
                "let's subsample the CIFAR-10 dataset uniformly to 10% of it's original size")
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")
    class_counts_df = class_distribution_df(trainset)
    fig = bar_chart_classes(class_counts_df)
    st.pyplot(fig)

    st.markdown("""We should now benchmark this base CIFAR-10 model with this subsampled training set. You can either 
    choose to load the CIFAR-10 base model that was included in the repository, or train a new one yourself on the 
    training set that was created to produce the previous bar char""")

    # Check if the cifar10_base_model_test.pt exists
    model_exists = os.path.exists("data/models/cifar10_base_model_test.pt")

    # Create two columns for placing the buttons side by side
    col1, col2 = st.columns(2)

    # Display the button for training the base model in the first column
    if col1.button('Train CIFAR-10 base model'):
        train_and_display('cifar_base', trainloader, testloader, device, epochs)

    # If the base model file exists, display the button for using the existing model in the second column
    if model_exists:
        if col2.button('Use existing CIFAR-10 base model'):
            # Instantiate the model and load the state_dict from the file
            st.session_state.cifar_net = Net()
            st.session_state.cifar_net.load_state_dict(torch.load("data/models/cifar10_base_model.pt"))
            st.session_state.cifar_net.to(device)

            # Calculate the metrics for the existing model
            cifar_metrics = calculate_metrics(st.session_state.cifar_net, testloader, device)
            st.session_state.cifar_net_accuracy = cifar_metrics['accuracy']
            st.session_state.cifar_net_per_class_accuracy = cifar_metrics['per_class_accuracy']

    # Show the net accuracy for the base model
    if 'cifar_base' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_base['metrics']['accuracy'] * 100:.2f}%")
        basecifar_fig = plot_single_per_class_accuracy(st.session_state.cifar_base['metrics']['per_class_accuracy'], labels,
                                                       'CFIAR-10 base model')
        st.pyplot(basecifar_fig)

    st.markdown("Great! We now have a base model trained on the subsampled CIFAR-10 dataset, and it should work "
                "reasonably well considering the simplicitly of our CNN and the size of the dataset. However, "
                "in real world applications we would be quite lucky to have a real dataset that is totally"
                "balanced across all class labels, so let's do some further ")

    # Create a button to decrease cat samples
    # If the button is pressed, show the slider and store its value in the session state
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")
    cat_proportion = st.slider("Total proportion of cat images:", min_value=0.0, max_value=0.09, value=0.05, step=0.01)
    st.session_state.cat_proportion = cat_proportion
    st.session_state.cat_num = cat_proportion * 10 * 500  # TODO: this should not be hardcoded like it is

    #
    # If the session state has a cat_proportion, use it to load the data and display the chart
    if "cat_proportion" in st.session_state:
        # TODO: to make this more performant, we should not be using load_cifar10 but instead subsample the
        #  trainset we already have
        trainset, trainloader, testset, testloader = load_cifar10(percentage=10,
                                                                  cat_proportion=st.session_state.cat_proportion)

        st.markdown("Let's take a look at the distribution of classes for our subsampled dataset now")
        class_counts_df = class_distribution_df(trainset)
        # TODO: maybe this chart can be replaced by a bokeh one
        fig = bar_chart_classes(class_counts_df)
        st.pyplot(fig)

        # We don't want the load_cifar10 function to run again unless there has been a change in cat_proportion,
        # so we delete the session state for the variable after using it
        del st.session_state.cat_proportion

    st.markdown("""Depending on your choice of the proportion of cat images, we should have an unbalanced dataset 
    with fewer cat images than any other class. This is a situation we would normally try to avoid, so obviously, 
    we should start adding our own synthetically created cat images to the training set to suppliment it!""")

    # ... (Load and transform synthetic images)
    synthetic_imgDir = "..\\syntheticDiffusion\\data\\synthetic_cats\\"
    custom_images = load_and_transform_images(synthetic_imgDir)
    custom_labels = len(custom_images) * [3]  # Your assigned labels(cat)

    # Define slider for selecting number of custom images to add
    st.markdown("""Use the slider below to set the number of synthetic cat images to add to the training data. 
    By default it's set to fill the missing number of cat images, however you can add as many or few as you'd like. 
    We can compare the relative performance by trying multiple values""")
    num_custom_images = st.slider('Select number of custom images to add to dataset', 0,
                                  (len(custom_images) - len(custom_images) % 50),
                                  value=(500 - int(st.session_state.cat_num)), step=50)

    # Normalize CIFAR-10 images
    cfar_images = [trainset[i][0] for i in range(len(trainset))]
    cfar_images = torch.stack(cfar_images)

    # Concatenate our synthetic images with CIFAR-10 images
    custom_train_images = torch.cat((cfar_images, custom_images[:num_custom_images]), dim=0)

    # Extract targets from the CIFAR-10 Subsample
    cfar_targets = [trainset[i][1] for i in range(len(trainset))]
    custom_train_labels = cfar_targets + custom_labels[:num_custom_images]

    # Create a custom dataloader for our new combined dataset
    custom_trainset = CustomDataset(custom_train_images, custom_train_labels)
    custom_trainloader = torch.utils.data.DataLoader(custom_trainset, batch_size=batch_size,
                                                     shuffle=True, num_workers=0)

    # Initialize variables to store the previous custom model's accuracies in the session state
    if 'prev_custom_net_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_accuracy = None

    if 'prev_custom_net_per_class_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_per_class_accuracy = None

    # Create a button for triggering the training process
    # if st.button('Train synthetically enhanced model'):
    #
    #     # Create instance of your model
    #     custom_net = Net()
    #     custom_net.to(device)
    #
    #     # Display a message while the model is being trained
    #     training_message = st.empty()
    #     training_message.text("Training custom model...")
    #
    #     # Create a progress bar
    #     progress_bar = st.progress(0)
    #
    #     # Train the networks using the custom and CIFAR-10 dataloaders
    #     train(custom_net, custom_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
    #           momentum=0.9,
    #           progress_callback=update_progress, progress_bar=progress_bar)
    #
    #     # Remove the progress bar after training is complete
    #     progress_bar.empty()
    #
    #     # Clear the message and display the results
    #     training_message.empty()
    #
    #     metrics = calculate_metrics(custom_net, testloader, device, len(classes))
    #
    #     # Display overall accuracy
    #     st.subheader("Overall Model Accuracy")
    #     st.write(f"Custom model accuracy: {metrics['accuracy'] * 100:.2f}%")
    #     # st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy:.2f}%")
    #
    #     # Plot per-class accuracy
    #     st.subheader("Per-class Model Accuracy")
    #
    #     fig = plot_per_class_accuracy(metrics, st.session_state.cifar_net_per_class_accuracy, labels,
    #                                   ['Custom model', 'CIFAR-10 Base model'])
    #
    #     st.pyplot(fig)
    #
    #     # Compare the new custom model with the previous custom model if it exists
    #     if st.session_state.prev_custom_net_accuracy is not None:
    #         st.subheader("Comparison with the Previous Custom Model")
    #         fig2 = plot_per_class_accuracy(metrics, st.session_state.prev_custom_net_per_class_accuracy, labels,
    #                                        ['Current Custom Model', 'Previous Custom Model'])
    #
    #         fig2.tight_layout()
    #
    #         st.pyplot(fig2)
    #
    #     # Store the previous custom model's accuracies before updating the current ones
    #     st.session_state.prev_custom_net_accuracy = metrics['accuracy']
    #     st.session_state.prev_custom_net_per_class_accuracy = metrics['per_class_accuracy']


def page5():
    # This page exists for debugging purposes

    import torch
    import io

    # ... your existing code ...

    if 'cifar_net_accuracy' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy * 100:.2f}%")

        # Save the model to a binary format (PyTorch)
        model_binary = io.BytesIO()
        torch.save(st.session_state.cifar_net.state_dict(), model_binary)
        model_binary.seek(0)

        # Create a download button for the model
        st.download_button(
            label="Download CIFAR-10 base model",
            data=model_binary,
            file_name="cifar10_base_model_test.pt",
            mime="application/octet-stream"
        )

def main():
    st.sidebar.title("Navigation")
    selected_page = st.sidebar.radio("Go to",
                                     ["Introduction", "Synthetic Cats", "Pre-calculated results", "Hands-on", "Debugging"])

    st.markdown("# Synthetic Diffusion")

    # Mapping of pages to their respective functions
    pages = {
        "Introduction": page1,
        "Synthetic Cats": page2,
        "Pre-calculated results": page3,
        "Hands-on": page4,
        "Debugging": page5
    }

    # Call the function corresponding to the selected page
    pages[selected_page]()

# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    main()



