import io
import os
import torch
import pandas as pd

import streamlit as st

from PIL import Image
from torch.utils.data import Subset

from src.data.data_utils import class_distribution_df, CustomDataset, load_and_transform_images, \
    load_cifar10_testset, load_cifar10_trainset
from src.viewer.visualization_utils import bar_chart_classes, plot_single_per_class_accuracy
from src.model.model import train_and_display, calculate_metrics, Net, perform_batch_training_and_metrics

torch.manual_seed(0)

# These are the classes in the cifar-10 dataset (in proper order)
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # TODO: do I still need this?

batch_size = 16
epochs = 30
num_classes = 10
cifar_percentage = 10

device = 'cuda' if torch.cuda.is_available() else 'cpu'  # If gpu exists use cuda
st.session_state.testset, st.session_state.testloader = load_cifar10_testset(batch_size)

# Load and transform synthetic cat images
synthetic_imgDir = "..\\syntheticDiffusion\\data\\synthetic_cats\\"
custom_images = load_and_transform_images(synthetic_imgDir)


def intro_page():
    st.title("Background")
    st.markdown("## What's it all about")
    st.markdown("""Welcome to this demonstration of using advanced techniques in artificial intelligence to generate 
    synthetic data for practical applications in data science. In this project, we'll be showcasing the power of Stable 
    Diffusion to generate synthetic data for a Convolutional Neural Network (CNN) image classification problem. By 
    augmenting our training data with synthetic images, we aim to improve the classification accuracy of the model. We've 
    chosen the CIFAR-10 dataset for this demonstration as it's lightweight and well-suited for our purposes. The CIFAR-10 
    dataset is widely recognized in the computer vision community, making it an ideal choice to demonstrate the 
    effectiveness of using synthetic data generated by Stable Diffusion.""")

    st.markdown("## CIFAR-10")
    st.markdown(" Let's take a look at the CIFAR-10 dataset")
    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cifar10.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='CIFAR-10 dataset example', use_column_width=True)

    st.markdown("## Methods")
    st.markdown("""
    The process we'll be following consists of three main steps:

    1. **Synthetic Data Generation**: We'll begin by generating a synthetic dataset of cat images using Stable Diffusion, 
    a powerful technique for creating realistic images that closely resemble their real-world counterparts. 

    2. **Data Transformation**: After obtaining the synthetic cat dataset, we'll transform it to match the format of the 
    CIFAR-10 dataset. This ensures that our CNN model can seamlessly process the synthetic data in conjunction with the 
    original dataset. 

    3. **Subsampling CIFAR-10**: To emphasize the impact of adding synthetic data to our model, we'll subsample the 
    CIFAR-10 dataset, working with a smaller number of images than typically used. This simulates a situation where 
    limited data is available, and the addition of synthetic images can provide a significant boost in classification 
    performance.

    By following these steps, we aim to demonstrate the potential benefits of incorporating synthetic data generated 
    using Stable Diffusion into a CNN model for image classification. This demonstration will showcase the practical 
    implications of using synthetic data to improve model performance in real-world applications.""")

    st.markdown("""
    Having generated a collection of realistic looking cat images we have to transform the format to match that of the
    CIFAR-10 dataset. The most important change is that we have to downsample our 512x512 images to 32x32""")

    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cat_to_cat.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='Resize of synthetic cat images to CIFAR-10 format', use_column_width=True)


def synCats_page():
    st.title("Generating Synthetic Images of cats")
    st.markdown("")
    st.markdown("[Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)",
                unsafe_allow_html=True)


def preCalc_page():

    # import plotly.graph_objects as go

    def create_interactive_plot(df):
        import plotly.graph_objs as go

        # Create a Plotly figure
        fig = go.Figure()

        # Define the metrics
        metrics = ['accuracy', 'per_class_accuracy', 'precision', 'recall', 'f1_score']

        # Add traces for each source and metric
        for metric in metrics:
            for source in df['source'].unique():
                visible = metric == 'accuracy'
                fig.add_trace(go.Scatter(x=df[(df['source'] == source) & (df['metric'] == metric)]['percentage'],
                                         y=df[(df['source'] == source) & (df['metric'] == metric)]['value'],
                                         mode='lines+markers',
                                         name=f"{source} {metric}",
                                         visible=visible))

        # Update layout with dropdown menu for metrics
        fig.update_layout(
            title="Comparison of Metrics for Real and Synthetic",
            xaxis_title="Percentage",
            yaxis_title="Value",
            updatemenus=[
                go.layout.Updatemenu(
                    buttons=list([
                        dict(label=metric,
                             method="update",
                             args=[{"visible": [m == metric for m in metrics for _ in range(2)]},
                                   {"title": metric}])
                        for metric in metrics
                    ]),
                    direction="down",
                    pad={"r": 10, "t": 10},
                    showactive=True,
                    x=0.1,
                    xanchor="left",
                    y=1.1,
                    yanchor="top",
                ),
            ]
        )

        return fig

    def create_comparison_plot(df1, df2, metric_names, class_index):
        # Add a 'source' column to identify the origin
        df1['source'] = 'Real'
        df2['source'] = 'Synthetic'

        # Melt the dataframes to a long format
        df1 = df1.melt(id_vars=['metric', 'source'], var_name='percentage', value_name='value')
        df2 = df2.melt(id_vars=['metric', 'source'], var_name='percentage', value_name='value')

        # Merge the two dataframes
        combined_df = pd.concat([df1, df2])

        # Filter rows based on the metric names
        #combined_df = combined_df[combined_df['metric'].isin(metric_names)]

        # Something weird is happening where the values in the dataframe are being saved as a string instead of a list,
        # let's convert these back into lists

        # Custom function to convert mixed format strings to either a single float or a list of floats
        def mixed_str_to_float(mixed_str):
            mixed_str = mixed_str.strip()
            if mixed_str.startswith('[') and mixed_str.endswith(']'):
                mixed_str = mixed_str[1:-1]  # Remove the brackets
                return [float(x) for x in mixed_str.split()]
            else:
                return float(mixed_str)

        # Apply the custom function to the DataFrame column
        combined_df['value'] = combined_df['value'].apply(mixed_str_to_float)

        # Modify this line in the `create_comparison_plot` function:
        combined_df.loc[combined_df['metric'] != 'accuracy', 'value'] = combined_df.loc[
            combined_df['metric'] != 'accuracy', 'value'].apply(lambda x: x[class_index])

        # Convert 'percentage' column to numeric type
        combined_df['percentage'] = pd.to_numeric(combined_df['percentage'])

        # Call the function with your DataFrame
        return create_interactive_plot(combined_df)


    df_real = pd.read_csv("data/precalc_metrics_real1.csv")
    df_syn = pd.read_csv("data/precalc_metrics_synthetic1.csv")

    metric_names = ['per_class_accuracy', 'precision', 'recall', 'f1_score']

    fig = create_comparison_plot(df_real, df_syn, metric_names, 3)
    st.plotly_chart(fig)

    # # Function to plot the line plot for each metric
    # def plot_metric(df, metric_name, class_index):
    #     fig = go.Figure()
    #
    #     for i in range(10):  # Assuming there are 10 classes in the CIFAR-10 dataset
    #         fig.add_trace(go.Scatter(x=df.columns[1:],
    #                                  y=[float(x.strip()[1:-1].split()[i]) for x in
    #                                     df.loc[df['metric'] == metric_name].values[0][1:]],
    #                                  mode='lines+markers',
    #                                  name=f'Class {i}'))
    #
    #     fig.update_layout(title=f'{metric_name} for Class {class_index} across Models',
    #                       xaxis_title='Percentage of Cat Images',
    #                       yaxis_title=f'{metric_name}')
    #
    #     return fig
    #
    # # Display line plots for each metric
    # st.plotly_chart(plot_metric(df_dummy, 'per_class_accuracy', 0))
    # st.plotly_chart(plot_metric(df_dummy, 'precision', 0))
    # st.plotly_chart(plot_metric(df_dummy, 'recall', 0))
    # st.plotly_chart(plot_metric(df_dummy, 'f1_score', 0))

    # def plot_accuracy():
    #     fig = go.Figure()
    #
    #     fig.add_trace(go.Scatter(x=df.columns[1:],
    #                              y=df.loc[df['metric'] == 'accuracy'].values[0][1:],
    #                              mode='lines+markers',
    #                              name='Accuracy'))
    #
    #     fig.update_layout(title='Overall Accuracy across Models',
    #                       xaxis_title='Percentage of Cat Images',
    #                       yaxis_title='Accuracy')
    #
    #     return fig
    #
    # st.plotly_chart(plot_accuracy())

    display_content = st.checkbox("Rerun models and benchmarking", value=False)
    if display_content:

        percentages = [0, 20, 40, 60, 80, 100]

        st.markdown("WARNING! Depending on how many trails you select, pressing the following button will take a long "
                    "time to complete")
        num_trials = st.selectbox('Select number of trails to run per % holdout of cat images:', list(range(1, 11)))

        if st.button("Perform batch training/metrics for real cats"):
            st.title("Pre-calculated results")
            metrics_df = perform_batch_training_and_metrics("real", num_trials, percentages, device)
            st.dataframe(metrics_df)

        if st.button("Perform batch training/metrics for synthetic cats"):
            st.title("Pre-calculated results")
            metrics_df = perform_batch_training_and_metrics("synthetic", num_trials, percentages, device, custom_images=custom_images)
            st.dataframe(metrics_df)




def handsOn_page():
    st.title("Experiment with Synthetic Diffusion")

    # Let's take a look at the distribution of classes in our CIFAR-10 subsample
    st.markdown("CIFAR-10 is a highly curated dataset with 50,000 images in the training set that are all perfectly "
                "balanced. Because we are doing some training and experimentation locally, we might not want to wait "
                "for a model to train using 50,000 images, additionally we really want to showcase the difference in "
                "performance when we are in a situation where we don't have all the data we would like, so right away "
                "let's subsample the CIFAR-10 dataset uniformly to 10% of it's original size")
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")

    st.markdown("Let's do some sampling")
    # Create a horizontal container
    container = st.container()
    sampling_method_options = ["uniform", "random"]
    selected_sampling_method = container.radio("Select sampling method", sampling_method_options, index=0)
    st.write(f"Selected sampling method: {selected_sampling_method}")

    trainset, trainloader = load_cifar10_trainset(cifar_percentage, batch_size, sample_method=selected_sampling_method)
    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    class_counts_df = class_distribution_df(trainset)
    fig = bar_chart_classes(class_counts_df)
    st.pyplot(fig)

    st.markdown("""We should now benchmark this base CIFAR-10 model with this subsampled training set. You can either 
    choose to load the CIFAR-10 base model that was included in the repository, or train a new one yourself on the 
    training set that was created to produce the previous bar char""")

    # Check if the cifar10_base_model.pt exists
    model_exists = os.path.exists("data/models/cifar10_base_model.pt")

    # Create two columns for placing the buttons side by side
    col1, col2 = st.columns(2)

    # Display the button for training the base model in the first column
    if col1.button('Train CIFAR-10 base model'):
        train_and_display('cifar_base', trainloader, st.session_state.testloader, device, epochs)

    # If the base model file exists, display the button for using the existing model in the second column
    if model_exists:
        if col2.button('Use existing CIFAR-10 base model'):
            # Instantiate the model and load the state_dict from the file
            st.session_state.cifar_net = Net()
            st.session_state.cifar_net.load_state_dict(torch.load("data/models/cifar10_base_model.pt"))
            st.session_state.cifar_net.to(device)

            # Calculate the metrics for the existing model
            cifar_metrics = calculate_metrics(st.session_state.cifar_net, st.session_state.testloader, device)
            st.session_state.cifar_net_accuracy = cifar_metrics['accuracy']
            st.session_state.cifar_net_per_class_accuracy = cifar_metrics['per_class_accuracy']

    # Show the net accuracy for the base model
    if 'cifar_base' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_base['metrics']['accuracy'] * 100:.2f}%")
        basecifar_fig = plot_single_per_class_accuracy(st.session_state.cifar_base['metrics']['per_class_accuracy'],
                                                       labels,
                                                       'CFIAR-10 base model')
        st.pyplot(basecifar_fig)

    st.markdown("Great! We now have a base model trained on the subsampled CIFAR-10 dataset, and it should work "
                "reasonably well considering the simplicitly of our CNN and the size of the dataset. However, "
                "in real world applications we would be quite lucky to have a real dataset that is totally"
                "balanced across all class labels, so let's do some further ")

    # Create a button to decrease cat samples
    # If the button is pressed, show the slider and store its value in the session state
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")
    cat_proportion = st.slider("% of total cat images to keep:", min_value=0, max_value=90, value=50, step=10)
    cat_proportion = max(0, cat_proportion / 100)
    st.session_state.cat_proportion = cat_proportion
    st.session_state.cat_num = cat_proportion * 10 * 500  # TODO: this should not be hardcoded like it is

    #
    # # If the session state has a cat_proportion, use it to load the data and display the chart
    # if "cat_proportion" in st.session_state:
    #     # TODO: to make this more performant, we should not be using load_cifar10 but instead subsample the
    #     #  trainset we already have
    #     trainset, trainloader, testset, testloader = load_cifar10(percentage=10,
    #                                                               cat_proportion=st.session_state.cat_proportion)
    #
    #     st.markdown("Let's take a look at the distribution of classes for our subsampled dataset now")
    #     class_counts_df = class_distribution_df(trainset)
    #     # TODO: maybe this chart can be replaced by a bokeh one
    #     fig = bar_chart_classes(class_counts_df)
    #     st.pyplot(fig)
    #
    #     # We don't want the load_cifar10 function to run again unless there has been a change in cat_proportion,
    #     # so we delete the session state for the variable after using it
    #     del st.session_state.cat_proportion

    st.markdown("""Depending on your choice of the proportion of cat images, we should have an unbalanced dataset 
    with fewer cat images than any other class. This is a situation we would normally try to avoid, so obviously, 
    we should start adding our own synthetically created cat images to the training set to suppliment it!""")

    # ... (Load and transform synthetic images)
    custom_labels = len(custom_images) * [3]  # Your assigned labels(cat)

    # Define slider for selecting number of custom images to add
    st.markdown("""Use the slider below to set the number of synthetic cat images to add to the training data. 
    By default it's set to fill the missing number of cat images, however you can add as many or few as you'd like. 
    We can compare the relative performance by trying multiple values""")
    num_custom_images = st.slider('Select number of custom images to add to dataset', 0,
                                  (len(custom_images) - len(custom_images) % 50),
                                  value=(500 - int(st.session_state.cat_num)), step=50)

    # Normalize CIFAR-10 images
    cfar_images = [trainset[i][0] for i in range(len(trainset))]
    cfar_images = torch.stack(cfar_images)

    # Concatenate our synthetic images with CIFAR-10 images
    custom_train_images = torch.cat((cfar_images, custom_images[:num_custom_images]), dim=0)

    # Extract targets from the CIFAR-10 Subsample
    cfar_targets = [trainset[i][1] for i in range(len(trainset))]
    custom_train_labels = cfar_targets + custom_labels[:num_custom_images]

    # Create a custom dataloader for our new combined dataset
    custom_trainset = CustomDataset(custom_train_images, custom_train_labels)
    custom_trainloader = torch.utils.data.DataLoader(custom_trainset, batch_size=batch_size,
                                                     shuffle=True, num_workers=0)

    # Initialize variables to store the previous custom model's accuracies in the session state
    if 'prev_custom_net_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_accuracy = None

    if 'prev_custom_net_per_class_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_per_class_accuracy = None

    # Create a button for triggering the training process
    # if st.button('Train synthetically enhanced model'):
    #
    #     # Create instance of your model
    #     custom_net = Net()
    #     custom_net.to(device)
    #
    #     # Display a message while the model is being trained
    #     training_message = st.empty()
    #     training_message.text("Training custom model...")
    #
    #     # Create a progress bar
    #     progress_bar = st.progress(0)
    #
    #     # Train the networks using the custom and CIFAR-10 dataloaders
    #     train(custom_net, custom_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
    #           momentum=0.9,
    #           progress_callback=update_progress, progress_bar=progress_bar)
    #
    #     # Remove the progress bar after training is complete
    #     progress_bar.empty()
    #
    #     # Clear the message and display the results
    #     training_message.empty()
    #
    #     metrics = calculate_metrics(custom_net, testloader, device, len(classes))
    #
    #     # Display overall accuracy
    #     st.subheader("Overall Model Accuracy")
    #     st.write(f"Custom model accuracy: {metrics['accuracy'] * 100:.2f}%")
    #     # st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy:.2f}%")
    #
    #     # Plot per-class accuracy
    #     st.subheader("Per-class Model Accuracy")
    #
    #     fig = plot_per_class_accuracy(metrics, st.session_state.cifar_net_per_class_accuracy, labels,
    #                                   ['Custom model', 'CIFAR-10 Base model'])
    #
    #     st.pyplot(fig)
    #
    #     # Compare the new custom model with the previous custom model if it exists
    #     if st.session_state.prev_custom_net_accuracy is not None:
    #         st.subheader("Comparison with the Previous Custom Model")
    #         fig2 = plot_per_class_accuracy(metrics, st.session_state.prev_custom_net_per_class_accuracy, labels,
    #                                        ['Current Custom Model', 'Previous Custom Model'])
    #
    #         fig2.tight_layout()
    #
    #         st.pyplot(fig2)
    #
    #     # Store the previous custom model's accuracies before updating the current ones
    #     st.session_state.prev_custom_net_accuracy = metrics['accuracy']
    #     st.session_state.prev_custom_net_per_class_accuracy = metrics['per_class_accuracy']


def comparison_page():
    st.markdown("Comparison with other methods like traditional cropping flipping...")


def network_page():
    st.markdown("Network")


def debugging_page():

    # ... your existing code ...

    if 'cifar_net_accuracy' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy * 100:.2f}%")

        # Save the model to a binary format (PyTorch)
        model_binary = io.BytesIO()
        torch.save(st.session_state.cifar_net.state_dict(), model_binary)
        model_binary.seek(0)

        # Create a download button for the model
        st.download_button(
            label="Download CIFAR-10 base model",
            data=model_binary,
            file_name="cifar10_base_model.pt",
            mime="application/octet-stream"
        )


def main():
    st.sidebar.title("Navigation")

    # Mapping of pages to their respective functions
    pages = {
        "Introduction": intro_page,
        "Synthetic Cats": synCats_page,
        # "Network": network_page,
        "Pre-calculated results": preCalc_page,
        "Hands-on": handsOn_page,
        "Comparison": comparison_page,
        "Debugging": debugging_page
    }

    page_list = list(pages.keys())

    selected_page = st.sidebar.radio("Go to", page_list)

    st.markdown("# Synthetic Diffusion")

    # Call the function corresponding to the selected page
    pages[selected_page]()


# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    main()
