import io
import os
import torch
import pandas as pd

import streamlit as st

from PIL import Image
from torch.utils.data import Subset

from src.data.data_utils import class_distribution_df, CustomDataset, load_and_transform_images, \
    load_cifar10_testset, load_cifar10_trainset, average_metrics
from src.viewer.visualization_utils import bar_chart_classes, plot_single_per_class_accuracy
from src.model.model import train_and_display, calculate_metrics, Net, train_and_evaluate_models

torch.manual_seed(0)

# These are the classes in the cifar-10 dataset (in proper order)
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # TODO: do I still need this?

batch_size = 16
epochs = 30
num_classes = 10
cifar_percentage = 10

device = 'cuda' if torch.cuda.is_available() else 'cpu'  # If gpu exists use cuda
st.session_state.testset, st.session_state.testloader = load_cifar10_testset(batch_size)

# Load and transform synthetic cat images
synthetic_imgDir = "..\\syntheticDiffusion\\data\\synthetic_cats\\"
custom_images = load_and_transform_images(synthetic_imgDir)


def intro_page():
    st.title("Background")
    st.markdown("## What's it all about")
    st.markdown("""Welcome to this demonstration of using advanced techniques in artificial intelligence to generate 
    synthetic data for practical applications in data science. In this project, we'll be showcasing the power of Stable 
    Diffusion to generate synthetic data for a Convolutional Neural Network (CNN) image classification problem. By 
    augmenting our training data with synthetic images, we aim to improve the classification accuracy of the model. We've 
    chosen the CIFAR-10 dataset for this demonstration as it's lightweight and well-suited for our purposes. The CIFAR-10 
    dataset is widely recognized in the computer vision community, making it an ideal choice to demonstrate the 
    effectiveness of using synthetic data generated by Stable Diffusion.""")

    st.markdown("## CIFAR-10")
    st.markdown(" Let's take a look at the CIFAR-10 dataset")
    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cifar10.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='CIFAR-10 dataset example', use_column_width=True)

    st.markdown("## Methods")
    st.markdown("""
    The process we'll be following consists of three main steps:

    1. **Synthetic Data Generation**: We'll begin by generating a synthetic dataset of cat images using Stable Diffusion, 
    a powerful technique for creating realistic images that closely resemble their real-world counterparts. 

    2. **Data Transformation**: After obtaining the synthetic cat dataset, we'll transform it to match the format of the 
    CIFAR-10 dataset. This ensures that our CNN model can seamlessly process the synthetic data in conjunction with the 
    original dataset. 

    3. **Subsampling CIFAR-10**: To emphasize the impact of adding synthetic data to our model, we'll subsample the 
    CIFAR-10 dataset, working with a smaller number of images than typically used. This simulates a situation where 
    limited data is available, and the addition of synthetic images can provide a significant boost in classification 
    performance.

    By following these steps, we aim to demonstrate the potential benefits of incorporating synthetic data generated 
    using Stable Diffusion into a CNN model for image classification. This demonstration will showcase the practical 
    implications of using synthetic data to improve model performance in real-world applications.""")

    st.markdown("""
    Having generated a collection of realistic looking cat images we have to transform the format to match that of the
    CIFAR-10 dataset. The most important change is that we have to downsample our 512x512 images to 32x32""")

    # Load the image using PIL
    image_path = '..\\syntheticDiffusion\\figures\\cat_to_cat.png'
    image = Image.open(image_path)

    # Display the image using Streamlit
    st.image(image, caption='Resize of synthetic cat images to CIFAR-10 format', use_column_width=True)


def synCats_page():
    st.title("Generating Synthetic Images of cats")
    st.markdown("")
    st.markdown("[Stable Diffusion Web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)",
                unsafe_allow_html=True)


def preCalc_page():
    def perform_batch_training_and_metrics(real_or_synthetic, num_trials, percentages, custom_images=None):
        """
        Performs batch training and metrics calculation for real or synthetic cats.

        This function loads the CIFAR-10 dataset, trains and evaluates models for each percentage of cat images,
        and calculates the average metrics across the specified number of trials. It returns a DataFrame with the
        averaged metrics and saves the results to a CSV file.

        Args:
            real_or_synthetic (str): A string indicating whether to use real cats ('real') or synthetic cats ('synthetic').
            num_trials (int): The number of trials to run per percentage holdout of cat images.
            percentages (list): A list of percentages of cat images to include in the training dataset.
            custom_images (torch.Tensor, optional): A tensor containing custom synthetic cat images. Required if real_or_synthetic is 'synthetic'.

        Returns:
            metrics_df (pd.DataFrame): A DataFrame containing the averaged metrics for each percentage of cat images.
        """
        # Function implementation...

        trainset, trainloader = load_cifar10_trainset()
        testset, testloader = load_cifar10_testset()

        all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device,
                                                custom_images=custom_images)
        averaged_metrics = average_metrics(all_metrics, num_trials)

        metrics_df = pd.DataFrame(averaged_metrics)

        if real_or_synthetic == "real":
            metrics_df.to_csv('data/precalc_metrics_real1.csv')
        else:
            metrics_df.to_csv('data/precalc_metrics_synthetic1.csv')

        return metrics_df

    display_content = st.checkbox("Rerun models and benchmarking", value=False)
    if display_content:

        percentages = [0, 20, 40, 60, 80, 100]

        st.markdown("WARNING! Depending on how many trails you select, pressing the following button will take a long "
                    "time to complete")
        num_trials = st.selectbox('Select number of trails to run per % holdout of cat images:', list(range(1, 11)))
        # if st.button("Perform batch training/metrics for real cats"):
        #     # trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
        #     trainset, trainloader = load_cifar10_trainset()
        #     testset, testloader = load_cifar10_testset()
        #
        #     st.title("Pre-calculated results")
        #
        #     # Assuming you have your trainset, trainloader, testloader, and device set up
        #     all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device)
        #     averaged_metrics = average_metrics(all_metrics, num_trials)
        #
        #     metrics_df = pd.DataFrame(averaged_metrics)
        #     metrics_df.to_csv('data/precalc_metrics_real1.csv')  # TODO: this does not save the correct name for the first
        #     # column, has to edited manually as 'metric'
        #     st.dataframe(metrics_df)
        #
        # if st.button("Perform batch training/metrics for synthetic cats"):
        #     # trainset, trainloader, testset, testloader = load_cifar10(cifar_percentage)
        #     trainset, trainloader = load_cifar10_trainset()
        #     testset, testloader = load_cifar10_testset()
        #
        #     st.title("Pre-calculated results")
        #
        #     # Assuming you have your trainset, trainloader, testloader, and device set up
        #     all_metrics = train_and_evaluate_models(percentages, num_trials, trainset, trainloader, testloader, device,
        #                                             custom_images=custom_images)
        #     averaged_metrics = average_metrics(all_metrics, num_trials)
        #
        #     metrics_df = pd.DataFrame(averaged_metrics)
        #     metrics_df.to_csv('data/precalc_metrics_synthetic1.csv')
        #     st.dataframe(metrics_df)
        if st.button("Perform batch training/metrics for real cats"):
            st.title("Pre-calculated results")
            metrics_df = perform_batch_training_and_metrics("real", num_trials, percentages)
            st.dataframe(metrics_df)

        if st.button("Perform batch training/metrics for synthetic cats"):
            st.title("Pre-calculated results")
            metrics_df = perform_batch_training_and_metrics("synthetic", num_trials, percentages, custom_images=custom_images)
            st.dataframe(metrics_df)

# def preCalc_page():
#
#     df = pd.read_csv("data/test.csv")
#     import plotly.graph_objects as go
#
#     # Function to plot the line plot for each metric
#     def plot_metric(metric_name, class_index):
#         fig = go.Figure()
#
#         for i in range(10):  # Assuming there are 10 classes in the CIFAR-10 dataset
#             fig.add_trace(go.Scatter(x=df.columns[1:],
#                                      y=[float(x.strip()[1:-1].split()[i]) for x in
#                                         df.loc[df['metric'] == metric_name].values[0][1:]],
#                                      mode='lines+markers',
#                                      name=f'Class {i}'))
#
#         fig.update_layout(title=f'{metric_name} for Class {class_index} across Models',
#                           xaxis_title='Percentage of Cat Images',
#                           yaxis_title=f'{metric_name}')
#
#         return fig
#
#     # Display line plots for each metric
#     st.plotly_chart(plot_metric('precision', 0))
#     st.plotly_chart(plot_metric('recall', 0))
#     st.plotly_chart(plot_metric('f1_score', 0))
#
#     def plot_accuracy():
#         fig = go.Figure()
#
#         fig.add_trace(go.Scatter(x=df.columns[1:],
#                                  y=df.loc[df['metric'] == 'accuracy'].values[0][1:],
#                                  mode='lines+markers',
#                                  name='Accuracy'))
#
#         fig.update_layout(title='Overall Accuracy across Models',
#                           xaxis_title='Percentage of Cat Images',
#                           yaxis_title='Accuracy')
#
#         return fig
#
#     st.plotly_chart(plot_accuracy())


def handsOn_page():
    st.title("Experiment with Synthetic Diffusion")

    # Let's take a look at the distribution of classes in our CIFAR-10 subsample
    st.markdown("CIFAR-10 is a highly curated dataset with 50,000 images in the training set that are all perfectly "
                "balanced. Because we are doing some training and experimentation locally, we might not want to wait "
                "for a model to train using 50,000 images, additionally we really want to showcase the difference in "
                "performance when we are in a situation where we don't have all the data we would like, so right away "
                "let's subsample the CIFAR-10 dataset uniformly to 10% of it's original size")
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")

    st.markdown("Let's do some sampling")
    # Create a horizontal container
    container = st.container()
    sampling_method_options = ["uniform", "random"]
    selected_sampling_method = container.radio("Select sampling method", sampling_method_options, index=0)
    st.write(f"Selected sampling method: {selected_sampling_method}")

    trainset, trainloader = load_cifar10_trainset(cifar_percentage, batch_size, sample_method=selected_sampling_method)
    labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']
    class_counts_df = class_distribution_df(trainset)
    fig = bar_chart_classes(class_counts_df)
    st.pyplot(fig)

    st.markdown("""We should now benchmark this base CIFAR-10 model with this subsampled training set. You can either 
    choose to load the CIFAR-10 base model that was included in the repository, or train a new one yourself on the 
    training set that was created to produce the previous bar char""")

    # Check if the cifar10_base_model.pt exists
    model_exists = os.path.exists("data/models/cifar10_base_model.pt")

    # Create two columns for placing the buttons side by side
    col1, col2 = st.columns(2)

    # Display the button for training the base model in the first column
    if col1.button('Train CIFAR-10 base model'):
        train_and_display('cifar_base', trainloader, st.session_state.testloader, device, epochs)

    # If the base model file exists, display the button for using the existing model in the second column
    if model_exists:
        if col2.button('Use existing CIFAR-10 base model'):
            # Instantiate the model and load the state_dict from the file
            st.session_state.cifar_net = Net()
            st.session_state.cifar_net.load_state_dict(torch.load("data/models/cifar10_base_model.pt"))
            st.session_state.cifar_net.to(device)

            # Calculate the metrics for the existing model
            cifar_metrics = calculate_metrics(st.session_state.cifar_net, st.session_state.testloader, device)
            st.session_state.cifar_net_accuracy = cifar_metrics['accuracy']
            st.session_state.cifar_net_per_class_accuracy = cifar_metrics['per_class_accuracy']

    # Show the net accuracy for the base model
    if 'cifar_base' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_base['metrics']['accuracy'] * 100:.2f}%")
        basecifar_fig = plot_single_per_class_accuracy(st.session_state.cifar_base['metrics']['per_class_accuracy'],
                                                       labels,
                                                       'CFIAR-10 base model')
        st.pyplot(basecifar_fig)

    st.markdown("Great! We now have a base model trained on the subsampled CIFAR-10 dataset, and it should work "
                "reasonably well considering the simplicitly of our CNN and the size of the dataset. However, "
                "in real world applications we would be quite lucky to have a real dataset that is totally"
                "balanced across all class labels, so let's do some further ")

    # Create a button to decrease cat samples
    # If the button is pressed, show the slider and store its value in the session state
    st.markdown("Let's take a look at the distribution of classes for our subsampled CIFAR-10 dataset")
    cat_proportion = st.slider("% of total cat images to keep:", min_value=0, max_value=90, value=50, step=10)
    cat_proportion = max(0, cat_proportion / 100)
    st.session_state.cat_proportion = cat_proportion
    st.session_state.cat_num = cat_proportion * 10 * 500  # TODO: this should not be hardcoded like it is

    #
    # # If the session state has a cat_proportion, use it to load the data and display the chart
    # if "cat_proportion" in st.session_state:
    #     # TODO: to make this more performant, we should not be using load_cifar10 but instead subsample the
    #     #  trainset we already have
    #     trainset, trainloader, testset, testloader = load_cifar10(percentage=10,
    #                                                               cat_proportion=st.session_state.cat_proportion)
    #
    #     st.markdown("Let's take a look at the distribution of classes for our subsampled dataset now")
    #     class_counts_df = class_distribution_df(trainset)
    #     # TODO: maybe this chart can be replaced by a bokeh one
    #     fig = bar_chart_classes(class_counts_df)
    #     st.pyplot(fig)
    #
    #     # We don't want the load_cifar10 function to run again unless there has been a change in cat_proportion,
    #     # so we delete the session state for the variable after using it
    #     del st.session_state.cat_proportion

    st.markdown("""Depending on your choice of the proportion of cat images, we should have an unbalanced dataset 
    with fewer cat images than any other class. This is a situation we would normally try to avoid, so obviously, 
    we should start adding our own synthetically created cat images to the training set to suppliment it!""")

    # ... (Load and transform synthetic images)
    custom_labels = len(custom_images) * [3]  # Your assigned labels(cat)

    # Define slider for selecting number of custom images to add
    st.markdown("""Use the slider below to set the number of synthetic cat images to add to the training data. 
    By default it's set to fill the missing number of cat images, however you can add as many or few as you'd like. 
    We can compare the relative performance by trying multiple values""")
    num_custom_images = st.slider('Select number of custom images to add to dataset', 0,
                                  (len(custom_images) - len(custom_images) % 50),
                                  value=(500 - int(st.session_state.cat_num)), step=50)

    # Normalize CIFAR-10 images
    cfar_images = [trainset[i][0] for i in range(len(trainset))]
    cfar_images = torch.stack(cfar_images)

    # Concatenate our synthetic images with CIFAR-10 images
    custom_train_images = torch.cat((cfar_images, custom_images[:num_custom_images]), dim=0)

    # Extract targets from the CIFAR-10 Subsample
    cfar_targets = [trainset[i][1] for i in range(len(trainset))]
    custom_train_labels = cfar_targets + custom_labels[:num_custom_images]

    # Create a custom dataloader for our new combined dataset
    custom_trainset = CustomDataset(custom_train_images, custom_train_labels)
    custom_trainloader = torch.utils.data.DataLoader(custom_trainset, batch_size=batch_size,
                                                     shuffle=True, num_workers=0)

    # Initialize variables to store the previous custom model's accuracies in the session state
    if 'prev_custom_net_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_accuracy = None

    if 'prev_custom_net_per_class_accuracy' not in st.session_state:
        st.session_state.prev_custom_net_per_class_accuracy = None

    # Create a button for triggering the training process
    # if st.button('Train synthetically enhanced model'):
    #
    #     # Create instance of your model
    #     custom_net = Net()
    #     custom_net.to(device)
    #
    #     # Display a message while the model is being trained
    #     training_message = st.empty()
    #     training_message.text("Training custom model...")
    #
    #     # Create a progress bar
    #     progress_bar = st.progress(0)
    #
    #     # Train the networks using the custom and CIFAR-10 dataloaders
    #     train(custom_net, custom_trainloader, device, epochs=epochs, print_every=4000, learning_rate=0.001,
    #           momentum=0.9,
    #           progress_callback=update_progress, progress_bar=progress_bar)
    #
    #     # Remove the progress bar after training is complete
    #     progress_bar.empty()
    #
    #     # Clear the message and display the results
    #     training_message.empty()
    #
    #     metrics = calculate_metrics(custom_net, testloader, device, len(classes))
    #
    #     # Display overall accuracy
    #     st.subheader("Overall Model Accuracy")
    #     st.write(f"Custom model accuracy: {metrics['accuracy'] * 100:.2f}%")
    #     # st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy:.2f}%")
    #
    #     # Plot per-class accuracy
    #     st.subheader("Per-class Model Accuracy")
    #
    #     fig = plot_per_class_accuracy(metrics, st.session_state.cifar_net_per_class_accuracy, labels,
    #                                   ['Custom model', 'CIFAR-10 Base model'])
    #
    #     st.pyplot(fig)
    #
    #     # Compare the new custom model with the previous custom model if it exists
    #     if st.session_state.prev_custom_net_accuracy is not None:
    #         st.subheader("Comparison with the Previous Custom Model")
    #         fig2 = plot_per_class_accuracy(metrics, st.session_state.prev_custom_net_per_class_accuracy, labels,
    #                                        ['Current Custom Model', 'Previous Custom Model'])
    #
    #         fig2.tight_layout()
    #
    #         st.pyplot(fig2)
    #
    #     # Store the previous custom model's accuracies before updating the current ones
    #     st.session_state.prev_custom_net_accuracy = metrics['accuracy']
    #     st.session_state.prev_custom_net_per_class_accuracy = metrics['per_class_accuracy']


def comparison_page():
    st.markdown("Comparison with other methods like traditional cropping flipping...")


def network_page():
    st.markdown("Network")


def debugging_page():

    # ... your existing code ...

    if 'cifar_net_accuracy' in st.session_state:
        st.write(f"CIFAR-10 model accuracy: {st.session_state.cifar_net_accuracy * 100:.2f}%")

        # Save the model to a binary format (PyTorch)
        model_binary = io.BytesIO()
        torch.save(st.session_state.cifar_net.state_dict(), model_binary)
        model_binary.seek(0)

        # Create a download button for the model
        st.download_button(
            label="Download CIFAR-10 base model",
            data=model_binary,
            file_name="cifar10_base_model.pt",
            mime="application/octet-stream"
        )


def main():
    st.sidebar.title("Navigation")

    # Mapping of pages to their respective functions
    pages = {
        "Introduction": intro_page,
        "Synthetic Cats": synCats_page,
        # "Network": network_page,
        "Pre-calculated results": preCalc_page,
        "Hands-on": handsOn_page,
        "Comparison": comparison_page,
        "Debugging": debugging_page
    }

    page_list = list(pages.keys())

    selected_page = st.sidebar.radio("Go to", page_list)

    st.markdown("# Synthetic Diffusion")

    # Call the function corresponding to the selected page
    pages[selected_page]()


# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    main()
